{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "904e69af",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaba2d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b98b42f",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfec6b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>ham</td>\n",
       "      <td>What is the plural of the noun research?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>ham</td>\n",
       "      <td>Going for dinner.msg you after.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm ok wif it cos i like 2 try new things. But...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>spam</td>\n",
       "      <td>GENT! We are trying to contact you. Last weeke...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wa, ur openin sentence very for</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     type                                               text  spam\n",
       "0     ham  Go until jurong point, crazy.. Available only ...     0\n",
       "1     ham                      Ok lar... Joking wif u oni...     0\n",
       "2    spam  Free entry in 2 a wkly comp to win FA Cup fina...     1\n",
       "3     ham  U dun say so early hor... U c already then say...     0\n",
       "4     ham  Nah I don't think he goes to usf, he lives aro...     0\n",
       "..    ...                                                ...   ...\n",
       "111   ham           What is the plural of the noun research?     0\n",
       "112   ham                    Going for dinner.msg you after.     0\n",
       "113   ham  I'm ok wif it cos i like 2 try new things. But...     0\n",
       "114  spam  GENT! We are trying to contact you. Last weeke...     1\n",
       "115   ham                    Wa, ur openin sentence very for     0\n",
       "\n",
       "[116 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"SPAM-210331-134237.csv\")\n",
    "data['spam'] = data['type'].map( {'spam':1,'ham':0} ).astype(int)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1467e131",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4517187f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ok lar... Joking wif u oni...'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad2ef440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ok', 'lar...', 'Joking', 'wif', 'u', 'oni...']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][1].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee66f624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(text):\n",
    "    return text.split()\n",
    "\n",
    "data['text'] = data['text'].apply(tokenization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23457032",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "449fe56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "SS = SnowballStemmer(\"english\",ignore_stopwords = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03fdccdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ok', 'lar...', 'Joking', 'wif', 'u', 'oni...']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bcf253b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stemming(text):\n",
    "    return [SS.stem(word) for word in text]\n",
    "\n",
    "data['text'] = data['text'].apply(Stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bc0912a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ok', 'lar...', 'joke', 'wif', 'u', 'oni...']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0619ae4",
   "metadata": {},
   "source": [
    "## Lemmitization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d783af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "LM = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42d549d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lemmatization(text):\n",
    "    return [LM.lemmatize(word,pos = \"a\") for word in text]\n",
    "\n",
    "data['text'] = data['text'].apply(Lemmatization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a566c4a",
   "metadata": {},
   "source": [
    "## Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8bfa15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "SW = stopwords.words(\"english\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65b4de32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def StopRemoval(text):\n",
    "    rev = [word for word in text if not word in SW]\n",
    "    return (rev)\n",
    "\n",
    "data['text'] = data['text'].apply(StopRemoval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f9bbd16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[go, jurong, point,, crazy.., avail, onli, bug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[ok, lar..., joke, wif, u, oni...]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[u, dun, say, earli, hor..., u, c, alreadi, sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[nah, think, goe, usf,, live, around, though]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>[freemsg, hey, darl, 3, week, word, back!, i'd...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>[even, brother, like, speak, me., treat, like,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>[per, request, mell, mell, (oru, minnaminungin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>[winner!!, valu, network, custom, select, rece...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>[mobil, 11, month, more?, u, r, entitl, updat,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text  spam\n",
       "0   ham  [go, jurong, point,, crazy.., avail, onli, bug...     0\n",
       "1   ham                 [ok, lar..., joke, wif, u, oni...]     0\n",
       "2  spam  [free, entri, 2, wkli, comp, win, fa, cup, fin...     1\n",
       "3   ham  [u, dun, say, earli, hor..., u, c, alreadi, sa...     0\n",
       "4   ham      [nah, think, goe, usf,, live, around, though]     0\n",
       "5  spam  [freemsg, hey, darl, 3, week, word, back!, i'd...     1\n",
       "6   ham  [even, brother, like, speak, me., treat, like,...     0\n",
       "7   ham  [per, request, mell, mell, (oru, minnaminungin...     0\n",
       "8  spam  [winner!!, valu, network, custom, select, rece...     1\n",
       "9  spam  [mobil, 11, month, more?, u, r, entitl, updat,...     1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08d6f84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fa0243c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go jurong point, crazy.. avail onli bugi n gre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar... joke wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkts 2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say earli hor... u c alreadi say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah think goe usf, live around though</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>freemsg hey darl 3 week word back! i'd like fu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>even brother like speak me. treat like aid pat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>per request mell mell (oru minnaminungint nuru...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>winner!! valu network custom select receivea Â£...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>mobil 11 month more? u r entitl updat late col...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text  spam\n",
       "0   ham  go jurong point, crazy.. avail onli bugi n gre...     0\n",
       "1   ham                        ok lar... joke wif u oni...     0\n",
       "2  spam  free entri 2 wkli comp win fa cup final tkts 2...     1\n",
       "3   ham          u dun say earli hor... u c alreadi say...     0\n",
       "4   ham              nah think goe usf, live around though     0\n",
       "5  spam  freemsg hey darl 3 week word back! i'd like fu...     1\n",
       "6   ham  even brother like speak me. treat like aid pat...     0\n",
       "7   ham  per request mell mell (oru minnaminungint nuru...     0\n",
       "8  spam  winner!! valu network custom select receivea Â£...     1\n",
       "9  spam  mobil 11 month more? u r entitl updat late col...     1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870cee5d",
   "metadata": {},
   "source": [
    "## Transforming into TDF/TF-IDF vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9371c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "y = data.spam.values\n",
    "x = tfidf.fit_transform(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72afa40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=10,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff18753",
   "metadata": {},
   "source": [
    "## Applying Logistics Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bd7f421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using Logistics: 83.33333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR = LogisticRegression()\n",
    "LR.fit(x_train,y_train)\n",
    "y_pred = LR.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "Acc_log = accuracy_score(y_pred, y_test) * 100\n",
    "print(\"Accuracy using Logistics:\",Acc_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0235962",
   "metadata": {},
   "source": [
    "## Applying LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c69f258b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using SVC: 83.33333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "LC = LinearSVC(random_state=0)\n",
    "LC.fit(x_train, y_train)\n",
    "y_pred = LC.predict(x_test)\n",
    "Acc_lvc = accuracy_score(y_pred, y_test) * 100\n",
    "print(\"Accuracy using SVC:\",Acc_lvc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a4c5c8",
   "metadata": {},
   "source": [
    "## Applying KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a667fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using Knn: 87.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(x_train,y_train)\n",
    "y_pred = knn.predict(x_test)\n",
    "Acc_knn = accuracy_score(y_pred,y_test) * 100\n",
    "print(\"Accuracy using Knn:\",Acc_knn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
